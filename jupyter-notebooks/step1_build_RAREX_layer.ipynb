{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RARE-X layer: Monoplex network of disease - patient - symptoms associations\n",
    "\n",
    "This code extracts disease - patient - symptoms associations from RARE-X anonymized patient data (file Survey_Symptoms_US.tsv). The network contains three types of nodes: disease, patient and symptom nodes, and two types of edges: disease-patient and patient-symptom edges. For the sake of simplicity, quantitative symptoms (i.e., CSHQ scores) are not taken into account for the construction of the network. The code generates the following monoplex network: ```network/multiplex/RARE_X/RARE_X_layer.tsv```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 diseases\n",
      "741 patients\n",
      "214 symptoms\n",
      "8 CSHQ scores\n"
     ]
    }
   ],
   "source": [
    "# read the data file\n",
    "df = pd.read_csv('../data/Survey_Symptoms_US.tsv',sep='\\t', header=0, index_col=0)\n",
    "df.head()\n",
    "\n",
    "# compute number of diseases, patients, symptoms and scores\n",
    "nb_diseases = (len(df[\"Disease Name\"].unique()))\n",
    "print(f\"{nb_diseases} diseases\")\n",
    "print(f\"{df.shape[0]} patients\")\n",
    "print(f\"{len(df.columns[0:214])} symptoms\")\n",
    "print(f\"{len(df.columns[214:222])} CSHQ scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Store disease-patient and patient-symptom associations in dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disease-patient and patient-symptom associations are stored into a dictionnary. CSHQ features are qualitatives values. We create a non weigthed Rare-X layer, so we decide to remove these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dico_diseases_patients(df: pd.DataFrame) -> dict():\n",
    "    \"\"\"\n",
    "    This function creates a dictionary of the diseases described in the \n",
    "    RARE-X data file, and their associated patients\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe containing the loaded RARE-X\n",
    "        data file\n",
    "    \n",
    "    Returns:\n",
    "        dict: a dictionay with the keys being the diseases described\n",
    "        in the data file and the values being the patients associated\n",
    "        with each disease\n",
    "    \"\"\"\n",
    "    # remove CSHQ scores columns !!A!! I don't get why this is here, CSHQ is more related with symptoms than disease or patients, no? And why remove ?\n",
    "    df = df.drop(df.columns[214:222], axis=1)\n",
    "    dico_diseases_patients = dict()\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if not row[\"Disease Name\"] in dico_diseases_patients.keys():\n",
    "            dico_diseases_patients[str(row[\"Disease Name\"])] = [index]\n",
    "        else:\n",
    "            dico_diseases_patients[str(row[\"Disease Name\"])] += [index]\n",
    "        i += 1\n",
    "    return(dico_diseases_patients)     \n",
    "\n",
    "dico_diseases_patients = build_dico_diseases_patients(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dico_patients_symptoms(df: pd.DataFrame) -> dict():\n",
    "    \"\"\"This function creates a dictionary of patients and\n",
    "    associated symtoms from the RARE-X data file\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe containing the \n",
    "        loaded RARE-X data\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary with the keys being the patients \n",
    "        described in the data file and the values being \n",
    "        their associated symptoms\n",
    "    \"\"\"\n",
    "    # remove CSHQ scores columns\n",
    "    df = df.drop(df.columns[214:222], axis=1)\n",
    "    dico_patients_symptoms = dict()\n",
    "    for index, row in df.iterrows():\n",
    "        symptoms = df.apply(lambda row: list(row.index[row == 1.0]), axis=1)\n",
    "        for index, columns in symptoms.iteritems():\n",
    "            dico_patients_symptoms[index] = columns\n",
    "    return dico_patients_symptoms\n",
    "\n",
    "dico_patients_symptoms = build_dico_patients_symptoms(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create mapping functions to map the diseases names to ORPHANET names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rare-X diseases need to be mapped to the Orphanet names. This mapping has been done manually and is provided as a dictionnary. Note that only 15 of the 27 Rare-X diseases can be mapped to OrphaCodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4H Leukodystrophy : 4H leukodystrophy \n",
      "\n",
      "8p-related disorders : 8p inverted duplication/deletion syndrome \n",
      "\n",
      "AHC (Alternating Hemiplegia of Childhood) : Alternating hemiplegia of childhood \n",
      "\n",
      "ARHGEF9-related disorders : None \n",
      "\n",
      "CACNA1A related disorders : None \n",
      "\n",
      "CASK-Related Disorders : None \n",
      "\n",
      "CHAMP1 related disorders : None \n",
      "\n",
      "CHD2 related disorders : None \n",
      "\n",
      "CHOPS Syndrome : Cognitive impairment-coarse facies-heart defects-obesity-pulmonary involvement-short stature-skeletal dysplasia syndrome \n",
      "\n",
      "Classic homocystinuria : Classic homocystinuria \n",
      "\n",
      "DYRK1A Syndrome : DYRK1A-related intellectual disability syndrome \n",
      "\n",
      "FAM177A1 Associated Disorder : None \n",
      "\n",
      "FOXP1 Syndrome : Intellectual disability-severe speech delay-mild dysmorphism syndrome \n",
      "\n",
      "HUWE1-related disorders : None \n",
      "\n",
      "KDM5C-related disorders : KDM5C-related syndromic X-linked intellectual disability \n",
      "\n",
      "Kleefstra syndrome : Kleefstra syndrome \n",
      "\n",
      "Koolen-de Vries Syndrome : Koolen-De Vries syndrome \n",
      "\n",
      "Malan Syndrome : Malan overgrowth syndrome \n",
      "\n",
      "MSL3 -related disorders : None \n",
      "\n",
      "NARS1 genetic mutation : None \n",
      "\n",
      "Ogden Syndrome (NAA10) : Ogden syndrome \n",
      "\n",
      "Pallister-Killian mosaic syndrome (PKS) : Tetrasomy 12p \n",
      "\n",
      "Ring14 and related disorders : None \n",
      "\n",
      "SETBP1-related disorder : None \n",
      "\n",
      "STXBP1 related Disorders : None \n",
      "\n",
      "SYNGAP1 related disorders : SYNGAP1-related developmental and epileptic encephalopathy \n",
      "\n",
      "Wiedemann-Steiner Syndrome (WSS) : Wiedemann-Steiner syndrome \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_mapping_file_diseases_names(mapping_file: str) -> dict:\n",
    "    \"\"\"This function creates a dictionary used for the mapping\n",
    "    of diseases names in the RARE-X data file to ORPHANET names\n",
    "\n",
    "    Args:\n",
    "        mapping_file (str): the file containing the mapping of\n",
    "        diseases idenfifiers\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary with keys being the diseases described in \n",
    "        the RARE-X data file and the values being their mapping \n",
    "        according to ORPHANET. If there is no corresponging \n",
    "        ORPHANET identifier, there is no mapping and the value\n",
    "        in the dictionary is set to \"None\"\n",
    "    \"\"\"\n",
    "    dico_mapping = dict()\n",
    "    mapping = pd.read_csv(mapping_file, sep=\";\", header=0)\n",
    "    for index, row in mapping.iterrows():\n",
    "        dico_mapping[str(row[0])] = row[1]\n",
    "    return dico_mapping\n",
    "\n",
    "dico_mapping = create_mapping_file_diseases_names(mapping_file=\"../data/Diseases_Rx_orpha_corres.csv\")\n",
    "for disease_rarex, disease_orpha in dico_mapping.items():\n",
    "    print(f\"{disease_rarex} : {disease_orpha} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_disease_name(name_to_map: str, mapping_dict: dict) -> str:\n",
    "    \"\"\"This function maps a disease name from the RARE-X data file\n",
    "    to its corresponding ORPHANET name from the mapping dictionary\n",
    "\n",
    "    Args:\n",
    "        name_to_map (str): the name of the disease to map\n",
    "        mapping_dict (dict): the mapping dictionary\n",
    "\n",
    "    Returns:\n",
    "        str: the ORPAHNET name of the disease if it exists, the \n",
    "        original name else\n",
    "    \"\"\"\n",
    "    return mapping_dict[name_to_map] if mapping_dict[name_to_map] != \"None\" else name_to_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Without the NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rarex_network_without_na(dico_diseases_patients: dict, dico_patients_symptoms: dict, mapping_dict: dict, network_filename: str) -> None:\n",
    "    \"\"\"This function allows to build the network of disease-patient-symptom associations.\n",
    "\n",
    "    Args:\n",
    "        dico_diseases_patients (dict): the dictionary of disease-patient associations\n",
    "        dico_patients_symptoms (dict): the dictionary of patient-symptom associations\n",
    "        mapping_dict (dict): the mapping dictionary\n",
    "        network_filename (str): the path to the generated network file\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    network = pd.DataFrame(columns=[\"source\", \"target\"])\n",
    "    i = 0\n",
    "    for disease in dico_diseases_patients.keys():\n",
    "        disease_orpha_name = map_disease_name(name_to_map=disease, mapping_dict=mapping_dict)\n",
    "        for patient in dico_diseases_patients[disease]:\n",
    "            network._set_value(i, \"source\", disease_orpha_name)\n",
    "            network._set_value(i, \"target\", patient)\n",
    "            i += 1\n",
    "    j = i+1\n",
    "    for patient in dico_patients_symptoms.keys():\n",
    "        for symptom in dico_patients_symptoms[patient]:\n",
    "            network._set_value(j, \"source\", patient)\n",
    "            network._set_value(j, \"target\", symptom)\n",
    "            j += 1\n",
    "    network.to_csv(network_filename, sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "build_rarex_network_without_na(\n",
    "                               dico_diseases_patients=dico_diseases_patients, \n",
    "                               dico_patients_symptoms=dico_patients_symptoms, \n",
    "                               mapping_dict=dico_mapping, \n",
    "                               network_filename=\"../network/multiplex/RARE_X/RARE_X_layer.tsv\"\n",
    "                               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "72de671574503e8c8ecd5c04b5d2eedcd345ef69975ded82916cca5b87de8e4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
