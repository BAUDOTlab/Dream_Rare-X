{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse MultiXrank results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the pipeline so far\n",
    "\n",
    "MultiXrank is a Random Walk with Restart algorithm designed to explore multilayer networks. Starting from a seed node, it assigns scores to all nodes in the network with respect to the seed. Theses scores indicate how close a network node is to the seed.\n",
    "\n",
    "We ran MultiXrank on a multilayer network composed of two layers:\n",
    "- the **Rare-X layer** contains disease (Rare-X name format), patient, and symptom nodes (file `network/multiplex/RareX_layer/RareX_layer.tsv`).\n",
    "All associations from the Rare-X layer are weighted:\n",
    "    - edges between **diseases and patients**: weights = 1\n",
    "    - edges between **patients and symptoms**:\n",
    "        - normalized CSHQ scores for CSHQ symptoms\n",
    "        - for other symptoms, we only put an edge if the patient presents the symptom, and theses edges are weighted 1\n",
    "\n",
    "- the **Orphanet layer** contains disease (Orphanet name format) and phenotypes (Human Phenotye Onthology HPO) nodes (file `network/multiplex/Orphanet_layer/Orphanet_layer.tsv`).\n",
    "All associations from the Orphanet layer are weighted:\n",
    "    - edges between **diseases**: weights = 1\n",
    "    - edges between **diseases and phenotypes**, weight is based on the association frequency from Orphanet:\n",
    "        - obligate (100%) -> weight = 1\n",
    "        - very frequent (99-80%) -> weight = 4/5\n",
    "        - frequent (79-30%) -> weight = 3/5\n",
    "        - occasional (29-5%) -> weight = 2/5\n",
    "        - very rare (<4-1%) -> weight = 1/5\n",
    "        - excluded (0%) -> weight = 0\n",
    "    - edges between **phenotypes**: weight = 0.2\n",
    "    \n",
    "Our hypothesis is that MultiXrank can uncover previously unknown symptoms associated with rare diseases. Taking iteratively each Rare-X disease as a seed, we hypothesise that MultiXrank can highlight the symptoms that have a high score with respect to the seed disease but do not have similar phenotypes with also a high score. These uncorrelated symptoms/phenotypes might indicate new and unrecognized aspects of the disease's phenotype, potentially leading to valuable insights for diagnosis and treatment.\n",
    "\n",
    "We run MultiXrank 27 times, using each time one of the 27 Rare-X diseases as seed. You can retreive the corresponding seed number in the `data/Diseases_names_and_seeds_numbering.tsv` file.\n",
    "\n",
    "We obtain two result files containing the node scores (one file for each layer analysed) for each MultiXrank run. \n",
    "\n",
    "In this notebook, we parse MultiXrank results to create a summary file for each disease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pyhpo import Ontology\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed to reshape the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Retreiving the phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we retreive the phenotypes from the Human Phenotype Onthology (HPO), stored in `en_product4.xml` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"../data/en_product4.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "# initilize the Ontology ()\n",
    "_ = Ontology()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Creating mapping between disease names and seed names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a mapping table between disease names and the seed numbers used in MultiXrank. We use the function `create_table_diseases_seeds()` to generate this mapping table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_diseases_seeds(mapping_file: str, table_name: str) -> dict:\n",
    "    \"\"\"Function that generates a mapping table of disease names and the \n",
    "    numbers used in MultiXrank to idenfity diseases\n",
    "\n",
    "    Args:\n",
    "        mapping_file (str): name of the mapping file\n",
    "        table_name (str): name of the output table\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary of correspondances between rare-x diseases names,\n",
    "        orphanet diseases names and seed numbers used in MultiXrank\n",
    "    \"\"\"\n",
    "    dico_diseases_seeds = dict()\n",
    "    df_mapping_file = pd.read_csv(mapping_file, sep=\";\", header=0)\n",
    "    df_table = pd.DataFrame(columns=[\"RARE-X\", \"ORPHANET\", \"SEED NUMBER\"])\n",
    "    df_table[\"RARE-X\"] = df_mapping_file[\"Rx\"]\n",
    "    diseases = df_table[\"RARE-X\"].tolist()\n",
    "    df_table[\"ORPHANET\"] = df_mapping_file[\"Orphanet\"]\n",
    "    seed_numbers = [i for i in range(1, 28)]\n",
    "    df_table[\"SEED NUMBER\"] = seed_numbers\n",
    "    df_table.to_csv(table_name, sep=\"\\t\", header=True, index=False)\n",
    "    for disease, seed in zip(diseases, seed_numbers):\n",
    "        dico_diseases_seeds[disease] = seed\n",
    "    return dico_diseases_seeds\n",
    "\n",
    "dico_diseases_seeds = create_table_diseases_seeds(mapping_file=\"../data/Diseases_Rx_orpha_corres.csv\", table_name=\"../data/Diseases_names_and_seeds_numbering.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Retrieving Orphanet names from Orphacodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_orpha_name()` function gives the disease Orphanet name for a given Orphanet code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_orpha_name(orpha_code: str) -> str:\n",
    "    \"\"\"Function that returns the orphanet\n",
    "    name of a disease given its orphanet\n",
    "    code\n",
    "\n",
    "    Args:\n",
    "        orpha_code (str): orphanet code of \n",
    "        the disease\n",
    "\n",
    "    Returns:\n",
    "        str: the orphanet name of the disease\n",
    "    \"\"\"\n",
    "    for disorder in root.iter('Disorder'):\n",
    "        orpha_code_in_tree = disorder.find('OrphaCode').text\n",
    "        orpha_name = disorder.find('Name').text\n",
    "        if orpha_code_in_tree == orpha_code:\n",
    "            return orpha_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Reshaping the results with the `create_results_table` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_results_table()` function reads the MultiXrank results files. Note that for each run done on a given seed, MultiXrank output two score files, one for each layer in the multilayer network (in our case, one for the Rare-X layer and one for the Orphanet layer).\n",
    "- MultiXrank results are stored in the `multiplex_RareX_layer.tsv` files for the Rare-X layer.\n",
    "- MultiXrank results are stored in the `multiplex_Orphanet_layer.tsv` files for the Orphanet layer.\n",
    "\n",
    "These files are large, and reading the entire files take time. Therefore, we only load the first 1000 lines of each file. You can change this number using the `input_nrow` parameter.\n",
    "\n",
    "The function adds the Orphanet disease name and the phenotype name for each corresponding Orphacode and phenotype that are in the Orphanet layer.  It also removes \"patient scores\" from the results of the Rare-X layer, since we are interested only in \"symptom scores\".\n",
    "\n",
    "We select the top 20 scores, to simplify the results analysis. You can change this top number using the `output_top` parameter. \n",
    "\n",
    "Finally, the function concatenates the top nodes from each layer into a single `tsv` file. The output directory name can be set up using the `resultsdir` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_table(dico_diseases_seeds: dict, input_nrow: int, output_top: int, outdir: str, resultsdir: str) -> None:\n",
    "    \"\"\"Function that generates for each MutliXrank output = \n",
    "    each rarex disease, a results file that recapitulates/concatenates \n",
    "    all the scores of the 2 layers in a single file\n",
    "\n",
    "    Args:\n",
    "        dico_diseases_seeds (dict): a dictionary of the rarex \n",
    "        diseases and their seed numbers used in MultiXrank\n",
    "        input_nrow (int): number of lines to read in MultiXrank outputs\n",
    "        output_top (int): number of top results to select for output\n",
    "        outdir (str): MultiXrank output directory\n",
    "        resultsdir (str): results output directory\n",
    "\n",
    "    Remark: read full output file could take time\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(f\"../results_MultiXrank/{resultsdir}/\", exist_ok=True)\n",
    "    for disease, seed in dico_diseases_seeds.items():\n",
    "        # Read layer 1 (rarex) output: no terms description to add\n",
    "        # because this layer contains Rare-X disease names, symptomes\n",
    "        # names and patients IDs\n",
    "        multiplex_layer1 = pd.read_csv(f\"../results_MultiXrank/{outdir}/output_{seed}/multiplex_RareX_layer.tsv\", header=0, sep=\"\\t\", nrows=input_nrow)\n",
    "        multiplex_layer1.rename(columns={\"multiplex\": \"layer\"}, inplace=True)\n",
    "        multiplex_1_selected = multiplex_layer1[multiplex_layer1['node'].str.contains('[A-Za-z]+', regex=True)]\n",
    "        \n",
    "        # Read layer 2 (orpha-hpo) output\n",
    "        multiplex_layer2 = pd.read_csv(f\"../results_MultiXrank/{outdir}/output_{seed}/multiplex_Orphanet_layer.tsv\", header=0, sep=\"\\t\", nrows=input_nrow)\n",
    "        multiplex_layer2.rename(columns={\"multiplex\": \"layer\"}, inplace=True)\n",
    "        # get the nodes into a list\n",
    "        nodes_layer2 = multiplex_layer2[multiplex_layer2.columns[1]].to_list()\n",
    "        # initialize empty list to store the descriptions (orpha names and phenotyes names) for each node\n",
    "        list_description_layer2 = list()\n",
    "        # browse nodes in mutliplex 2 to add description\n",
    "        for term in nodes_layer2:\n",
    "            if term[:5] == \"ORPHA\":\n",
    "                orpha_code = term[6:]\n",
    "                orpha_name = find_orpha_name(orpha_code=orpha_code)\n",
    "                list_description_layer2.append(orpha_name)\n",
    "            elif term[:2] == \"HP\":\n",
    "                try:\n",
    "                    hpo_phenotype = Ontology.get_hpo_object(term)\n",
    "                    list_description_layer2.extend([str(hpo_phenotype)[13:]])\n",
    "                # if there is no match of HPO phenotype name\n",
    "                except RuntimeError:\n",
    "                    list_description_layer2.append(\"None\")\n",
    "        # check that the description list and the dataframe have the same length !\n",
    "        assert len(list_description_layer2) == len(multiplex_layer2.index)\n",
    "        # create new description columns for the terms\n",
    "        description_layer2 = pd.DataFrame(list_description_layer2, columns=['description'])\n",
    "        # create new dataframe for layer 2 containing the ranking of the nodes + their description (orpha names and phenotypes names)\n",
    "        multiplex_2_with_description = pd.concat([multiplex_layer2.reindex(range(len(multiplex_layer2))), description_layer2.reindex(range(len(multiplex_layer2)))], axis=1)\n",
    "        \n",
    "        # Select top of results\n",
    "        multiplex_1_head = multiplex_1_selected.reset_index(drop=True).head(21)\n",
    "        multiplex_1_head[\"empty\"] = \"\"\n",
    "        multiplex_2_head = multiplex_2_with_description.reset_index(drop=True).head(21)\n",
    "        \n",
    "        # concatenate the two dataframes and generate table output\n",
    "        table_results = pd.concat([multiplex_1_head, multiplex_2_head], axis=1)\n",
    "        table_results.to_csv(f\"../results_MultiXrank/{resultsdir}/results_disease_{seed}.tsv\", sep=\"\\t\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "outdir = \"output\"\n",
    "resultsdir = \"results\"\n",
    "input_nrow = 1000\n",
    "output_top = 21\n",
    "\n",
    "## Results integration\n",
    "create_results_table(dico_diseases_seeds=dico_diseases_seeds,\n",
    "                     input_nrow=input_nrow, \n",
    "                     output_top=output_top,\n",
    "                     outdir=outdir, \n",
    "                     resultsdir=resultsdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
