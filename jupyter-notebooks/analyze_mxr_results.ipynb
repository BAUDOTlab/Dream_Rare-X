{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MultiXrank results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pyhpo import Ontology\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"../data/en_product4.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "# initilize the Ontology ()\n",
    "_ = Ontology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_orpha_name(orpha_code: str):\n",
    "    for disorder in root.iter('Disorder'):\n",
    "        orpha_code_in_tree = disorder.find('OrphaCode').text\n",
    "        orpha_name = disorder.find('Name').text\n",
    "        if orpha_code_in_tree == orpha_code:\n",
    "            return orpha_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_diseases_seeds(mapping_file: str, table_name: str) -> dict:\n",
    "    dico_diseases_seeds = dict()\n",
    "    df_mapping_file = pd.read_csv(mapping_file, sep=\";\", header=0)\n",
    "    df_table = pd.DataFrame(columns=[\"RARE-X\", \"ORPHANET\", \"SEED NUMBER\"])\n",
    "    df_table[\"RARE-X\"] = df_mapping_file[\"Rx\"]\n",
    "    diseases = df_table[\"RARE-X\"].tolist()\n",
    "    df_table[\"ORPHANET\"] = df_mapping_file[\"Orphanet\"]\n",
    "    seed_numbers = [i for i in range(1, 28)]\n",
    "    df_table[\"SEED NUMBER\"] = seed_numbers\n",
    "    df_table.to_csv(table_name, sep=\"\\t\", header=True, index=False)\n",
    "    for disease, seed in zip(diseases, seed_numbers):\n",
    "        dico_diseases_seeds[disease] = seed\n",
    "    return dico_diseases_seeds\n",
    "\n",
    "dico_diseases_seeds = create_table_diseases_seeds(mapping_file=\"../Diseases_Rx_orpha_corres.csv\", table_name=\"../Diseases_names_and_seeds_numbering.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12545\n",
      "RangeIndex(start=0, stop=12545, step=1)\n",
      "2771\n",
      "RangeIndex(start=0, stop=2771, step=1)\n",
      "2771\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s0/t5nj_65918jd2hdrt39p32v80000gn/T/ipykernel_35999/3235121286.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtable_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../multixrank_RARE_X_diseases/analysis_results/results_disease_{seed}.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mcreate_results_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdico_diseases_seeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdico_diseases_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/s0/t5nj_65918jd2hdrt39p32v80000gn/T/ipykernel_35999/3235121286.py\u001b[0m in \u001b[0;36mcreate_results_table\u001b[0;34m(dico_diseases_seeds)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ORPHA\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0morpha_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0morpha_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_orpha_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morpha_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morpha_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mlist_description_layer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morpha_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"HP\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/s0/t5nj_65918jd2hdrt39p32v80000gn/T/ipykernel_35999/1776107744.py\u001b[0m in \u001b[0;36mfind_orpha_name\u001b[0;34m(orpha_code)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_orpha_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morpha_code\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdisorder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Disorder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0morpha_code_in_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OrphaCode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0morpha_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morpha_code_in_tree\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0morpha_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_results_table(dico_diseases_seeds: dict) -> None:\n",
    "    for disease, seed in dico_diseases_seeds.items():\n",
    "        # Read layer 1 (rarex): no terms description to add\n",
    "        multiplex_layer1 = pd.read_csv(f\"../multixrank_RARE_X_diseases/output_multixrank/output_{seed}/multiplex_1.tsv\", header=0, sep=\"\\t\")\n",
    "        \n",
    "        # Read layer 2 (orpha-hpo) and fetch term description\n",
    "        multiplex_layer2 = pd.read_csv(f\"../multixrank_RARE_X_diseases/output_multixrank/output_{seed}/multiplex_2.tsv\", header=0, sep=\"\\t\")\n",
    "        nodes_layer2 = multiplex_layer2[multiplex_layer2.columns[1]].to_list()\n",
    "        list_description_layer2 = list()\n",
    "        # browse terms in mutliplex 2 to add description\n",
    "        for term in nodes_layer2:\n",
    "            if term[:5] == \"ORPHA\":\n",
    "                orpha_code = term[6:]\n",
    "                orpha_name = find_orpha_name(orpha_code=orpha_code)\n",
    "                list_description_layer2.append(orpha_name)\n",
    "            elif term[:2] == \"HP\":\n",
    "                try:\n",
    "                    hpo_phenotype = Ontology.get_hpo_object(term)\n",
    "                    list_description_layer2.extend([str(hpo_phenotype)[13:]])\n",
    "                except RuntimeError:\n",
    "                    list_description_layer2.append(\"None\")\n",
    "        # check that the description list and the dataframe have the same length\n",
    "        assert len(list_description_layer2) == len(multiplex_layer2.index)\n",
    "        # create new description columns for the terms\n",
    "        description_layer2 = pd.DataFrame(list_description_layer2, columns=['description'])\n",
    "        print(len(list_description_layer2))\n",
    "        print(multiplex_layer2)\n",
    "        multiplex_2_with_description = pd.concat([multiplex_layer2.reindex(range(len(multiplex_layer2))), description_layer2.reindex(range(len(multiplex_layer2)))], axis=1)\n",
    "\n",
    "        # read layer 3 (disease similaruty) and fetch orpha diseases descriptions\n",
    "        multiplex_layer3 = pd.read_csv(f\"../multixrank_RARE_X_diseases/output_multixrank/output_{seed}/multiplex_3.tsv\", header=0, sep=\"\\t\")\n",
    "        nodes_layer3 = multiplex_layer3[multiplex_layer3.columns[1]].to_list()\n",
    "        list_description_layer3 = list()\n",
    "        for term in nodes_layer3:\n",
    "                orpha_code = term[6:]\n",
    "                orpha_name = find_orpha_name(orpha_code=orpha_code)\n",
    "                list_description_layer3.append(orpha_name)\n",
    "        # check lengths\n",
    "        assert len(list_description_layer3) == len(multiplex_layer3.index)\n",
    "        # create new column for description of orpha diseases\n",
    "        description_layer3 = pd.DataFrame(list_description_layer3, columns=['description'])\n",
    "        print(len(list_description_layer3))\n",
    "        print(len(multiplex_layer3))\n",
    "        multiplex_layer3_with_description = pd.concat([multiplex_layer3.reindex(range(len(multiplex_layer3))), description_layer3.reindex(range(len(multiplex_layer3)))], axis=1)\n",
    "        \n",
    "        # concatenate the three dataframes\n",
    "        max_rows = max(len(multiplex_layer1), len(multiplex_2_with_description), len(multiplex_layer3_with_description))\n",
    "        table_results = pd.concat([multiplex_layer1.reindex(range(max_rows)), multiplex_2_with_description.reindex(range(max_rows)), multiplex_layer3_with_description.reindex(range(max_rows))], axis=1)\n",
    "        \n",
    "        table_results.to_csv(f\"../multixrank_RARE_X_diseases/analysis_results/results_disease_{seed}.tsv\", sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "create_results_table(dico_diseases_seeds=dico_diseases_seeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
