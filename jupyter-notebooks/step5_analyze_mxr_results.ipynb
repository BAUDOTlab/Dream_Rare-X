{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MultiXrank results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiXrank is a Random Walk with Restart algorithm designed for multilayer networks. Starting from a seed node, it assigns scores to all nodes in the network. Theses scores indicate how closely connected a node is to the seed.\n",
    "\n",
    "Our multilayer network consists of two layers: the Rare-X layer containing diseases, patients, and symptom nodes, and the Orphanet layer containing diseases and Human Phenotype Ontology (HPO) nodes.\n",
    "\n",
    "Our hypothesis is that MultiXrank can uncover previously unknown phenotypes associated with rare diseases. Taking iteratively each rare disease as a seed, we hypothesise that MultiXrank can identify symptoms that have a strong connection to the seed disease but are not represented in the HPO terms associated with that disease. These uncorrelated symptoms might indicate new and unrecognized aspects of the disease's phenotype, potentially leading to valuable insights for diagnosis and treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pyhpo import Ontology\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"../data/en_product4.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "# initilize the Ontology ()\n",
    "_ = Ontology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_orpha_name(orpha_code: str) -> str:\n",
    "    \"\"\"Function that returns the orphanet\n",
    "    name of a disease given its orphanet\n",
    "    code\n",
    "\n",
    "    Args:\n",
    "        orpha_code (str): orphanet code of \n",
    "        the disease\n",
    "\n",
    "    Returns:\n",
    "        str: the orphanet name of the disease\n",
    "    \"\"\"\n",
    "    for disorder in root.iter('Disorder'):\n",
    "        orpha_code_in_tree = disorder.find('OrphaCode').text\n",
    "        orpha_name = disorder.find('Name').text\n",
    "        if orpha_code_in_tree == orpha_code:\n",
    "            return orpha_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_diseases_seeds(mapping_file: str, table_name: str) -> dict:\n",
    "    \"\"\"Function that generates a mapping table of disease names and the \n",
    "    numbers used in multixrank to idenfity diseases\n",
    "\n",
    "    Args:\n",
    "        mapping_file (str): name of the mapping file\n",
    "        table_name (str): name of the output table\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary of correspondances between rare-x diseases names,\n",
    "        orphanet diseases names and seed numbers used in multixrank\n",
    "    \"\"\"\n",
    "    dico_diseases_seeds = dict()\n",
    "    df_mapping_file = pd.read_csv(mapping_file, sep=\";\", header=0)\n",
    "    df_table = pd.DataFrame(columns=[\"RARE-X\", \"ORPHANET\", \"SEED NUMBER\"])\n",
    "    df_table[\"RARE-X\"] = df_mapping_file[\"Rx\"]\n",
    "    diseases = df_table[\"RARE-X\"].tolist()\n",
    "    df_table[\"ORPHANET\"] = df_mapping_file[\"Orphanet\"]\n",
    "    seed_numbers = [i for i in range(1, 28)]\n",
    "    df_table[\"SEED NUMBER\"] = seed_numbers\n",
    "    df_table.to_csv(table_name, sep=\"\\t\", header=True, index=False)\n",
    "    for disease, seed in zip(diseases, seed_numbers):\n",
    "        dico_diseases_seeds[disease] = seed\n",
    "    return dico_diseases_seeds\n",
    "\n",
    "dico_diseases_seeds = create_table_diseases_seeds(mapping_file=\"../data/Diseases_Rx_orpha_corres.csv\", table_name=\"../Diseases_names_and_seeds_numbering.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionnary with the correspondance table (orpha vs rare x disease names)\n",
    "dico_mapping = dict()\n",
    "mapping = pd.read_csv(f\"../network/bipartite/bipartite_RARE_X_orpha_diseases.tsv\", header=None, sep=\"\\t\")\n",
    "for index, row in mapping.iterrows():\n",
    "    dico_mapping[str(row[0])] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"output_DiseaseDisease_Phenotype_Weighted\"\n",
    "resultsdir = \"results_output_DiseaseDisease_Phenotype_Weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_table(dico_diseases_seeds: dict) -> None:\n",
    "    \"\"\"Function that generates for each mutlixrank output = \n",
    "    each rarex disease, a results file that recapitulates/concatenates \n",
    "    all the scores of the 3 layers in a single file\n",
    "\n",
    "    Args:\n",
    "        dico_diseases_seeds (dict): a dictionary of the rarex \n",
    "        diseases and their seed numbers used in multixrank\n",
    "\n",
    "    Remark: not really optimized, can be long to run\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(f\"../multixrank_RARE_X_diseases/{resultsdir}/\", exist_ok=True)\n",
    "    # for each disease: read multixrank outputs\n",
    "    for disease, seed in dico_diseases_seeds.items():\n",
    "        # Read layer 1 (rarex) output: no terms description to add\n",
    "        # because this layer contains RARE-X disease names, symptomes\n",
    "        # names and patients IDs\n",
    "        multiplex_layer1 = pd.read_csv(f\"../multixrank_RARE_X_diseases/{outdir}/output_{seed}/multiplex_Rare_X_layer.tsv\", header=0, sep=\"\\t\")\n",
    "        # get nodes into a list\n",
    "        nodes_layer1 = multiplex_layer1[multiplex_layer1.columns[1]].to_list()\n",
    "        # initialize empty list to store the descriptions (corresponding orpha names) for each node\n",
    "        list_description_layer1 = list()\n",
    "        # browse nodes in mutliplex 1 to add description\n",
    "        for term in nodes_layer1:\n",
    "            if term in dico_mapping:\n",
    "                list_description_layer1.append(dico_mapping[term])\n",
    "            else:\n",
    "                list_description_layer1.append('None')\n",
    "        # check that the description list and the dataframe have the same length !\n",
    "        assert len(list_description_layer1) == len(multiplex_layer1.index)\n",
    "        # create new description columns for the terms\n",
    "        description_layer1 = pd.DataFrame(list_description_layer1, columns=['OrphaCorres'])\n",
    "        # create new dataframe for layer 1 containing the ranking of the nodes + their description (orpha names and phenotypes names)\n",
    "        multiplex_1_with_description = pd.concat([multiplex_layer1.reindex(range(len(multiplex_layer1))), description_layer1.reindex(range(len(multiplex_layer1)))], axis=1)\n",
    "\n",
    "        # Read layer 2 (orpha-hpo) output\n",
    "        multiplex_layer2 = pd.read_csv(f\"../multixrank_RARE_X_diseases/{outdir}/output_{seed}/multiplex_Orpha_layer.tsv\", header=0, sep=\"\\t\")\n",
    "        # get the nodes into a list\n",
    "        nodes_layer2 = multiplex_layer2[multiplex_layer2.columns[1]].to_list()\n",
    "        # initialize empty list to store the descriptions (orpha names and phenotyes names) for each node\n",
    "        list_description_layer2 = list()\n",
    "        # browse nodes in mutliplex 2 to add description\n",
    "        for term in nodes_layer2:\n",
    "            if term[:5] == \"ORPHA\":\n",
    "                orpha_code = term[6:]\n",
    "                orpha_name = find_orpha_name(orpha_code=orpha_code)\n",
    "                list_description_layer2.append(orpha_name)\n",
    "            elif term[:2] == \"HP\":\n",
    "                try:\n",
    "                    hpo_phenotype = Ontology.get_hpo_object(term)\n",
    "                    list_description_layer2.extend([str(hpo_phenotype)[13:]])\n",
    "                # if there is no match of HPO phenotype name\n",
    "                except RuntimeError:\n",
    "                    list_description_layer2.append(\"None\")\n",
    "        # check that the description list and the dataframe have the same length !\n",
    "        assert len(list_description_layer2) == len(multiplex_layer2.index)\n",
    "        # create new description columns for the terms\n",
    "        description_layer2 = pd.DataFrame(list_description_layer2, columns=['description'])\n",
    "        # create new dataframe for layer 2 containing the ranking of the nodes + their description (orpha names and phenotypes names)\n",
    "        multiplex_2_with_description = pd.concat([multiplex_layer2.reindex(range(len(multiplex_layer2))), description_layer2.reindex(range(len(multiplex_layer2)))], axis=1)\n",
    "\n",
    "        # concatenate the three dataframes and generate table output\n",
    "        max_rows = max(len(multiplex_layer1), len(multiplex_2_with_description))\n",
    "\n",
    "        table_results = pd.concat([multiplex_1_with_description.reindex(range(max_rows)), multiplex_2_with_description.reindex(range(max_rows))], axis=1)\n",
    "        table_results.to_csv(f\"../multixrank_RARE_X_diseases/{resultsdir}/results_disease_{seed}.tsv\", sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "create_results_table(dico_diseases_seeds=dico_diseases_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
