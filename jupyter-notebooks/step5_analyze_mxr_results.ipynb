{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze MultiXrank results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiXrank is a Random Walk with Restart algorithm designed to explore multilayer networks. Starting from a seed node, it assigns scores to all nodes in the network with respect to the seed. Theses scores indicate how close a network node is to the seed.\n",
    "\n",
    "Our multilayer network consists of two layers: the Rare-X layer containing disease (Rare-X name format), patient, and symptom nodes, and the Orphanet layer containing disease (Orphanet name format) and Human Phenotype Ontology (HPO) nodes.\n",
    "\n",
    "Our hypothesis is that MultiXrank can uncover previously unknown phenotypes associated with rare diseases. Taking iteratively each Rare-X disease as a seed, we hypothesise that MultiXrank can highlight the symptoms that have a high score with respect to the seed disease but do not have similar HPO terms with also a high score. These uncorrelated symptoms/HPO terms might indicate new and unrecognized aspects of the disease's phenotype, potentially leading to valuable insights for diagnosis and treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pyhpo import Ontology\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"../data/en_product4.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "# initilize the Ontology ()\n",
    "_ = Ontology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_orpha_name(orpha_code: str) -> str:\n",
    "    \"\"\"Function that returns the orphanet\n",
    "    name of a disease given its orphanet\n",
    "    code\n",
    "\n",
    "    Args:\n",
    "        orpha_code (str): orphanet code of \n",
    "        the disease\n",
    "\n",
    "    Returns:\n",
    "        str: the orphanet name of the disease\n",
    "    \"\"\"\n",
    "    for disorder in root.iter('Disorder'):\n",
    "        orpha_code_in_tree = disorder.find('OrphaCode').text\n",
    "        orpha_name = disorder.find('Name').text\n",
    "        if orpha_code_in_tree == orpha_code:\n",
    "            return orpha_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_diseases_seeds(mapping_file: str, table_name: str) -> dict:\n",
    "    \"\"\"Function that generates a mapping table of disease names and the \n",
    "    numbers used in multixrank to idenfity diseases\n",
    "\n",
    "    Args:\n",
    "        mapping_file (str): name of the mapping file\n",
    "        table_name (str): name of the output table\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary of correspondances between rare-x diseases names,\n",
    "        orphanet diseases names and seed numbers used in multixrank\n",
    "    \"\"\"\n",
    "    dico_diseases_seeds = dict()\n",
    "    df_mapping_file = pd.read_csv(mapping_file, sep=\";\", header=0)\n",
    "    df_table = pd.DataFrame(columns=[\"RARE-X\", \"ORPHANET\", \"SEED NUMBER\"])\n",
    "    df_table[\"RARE-X\"] = df_mapping_file[\"Rx\"]\n",
    "    diseases = df_table[\"RARE-X\"].tolist()\n",
    "    df_table[\"ORPHANET\"] = df_mapping_file[\"Orphanet\"]\n",
    "    seed_numbers = [i for i in range(1, 28)]\n",
    "    df_table[\"SEED NUMBER\"] = seed_numbers\n",
    "    df_table.to_csv(table_name, sep=\"\\t\", header=True, index=False)\n",
    "    for disease, seed in zip(diseases, seed_numbers):\n",
    "        dico_diseases_seeds[disease] = seed\n",
    "    return dico_diseases_seeds\n",
    "\n",
    "dico_diseases_seeds = create_table_diseases_seeds(mapping_file=\"../data/Diseases_Rx_orpha_corres.csv\", table_name=\"../Diseases_names_and_seeds_numbering.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionnary with the correspondance table (orpha vs rare x disease names)\n",
    "dico_mapping = dict()\n",
    "mapping = pd.read_csv(f\"../network/bipartite/bipartite_RARE_X_orpha_diseases.tsv\", header=None, sep=\"\\t\")\n",
    "for index, row in mapping.iterrows():\n",
    "    dico_mapping[str(row[0])] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_table(dico_diseases_seeds: dict, input_nrow: int, output_top: int, outdir: str, resultsdir: str) -> None:\n",
    "    \"\"\"Function that generates for each mutlixrank output = \n",
    "    each rarex disease, a results file that recapitulates/concatenates \n",
    "    all the scores of the 2 layers in a single file\n",
    "\n",
    "    Args:\n",
    "        dico_diseases_seeds (dict): a dictionary of the rarex \n",
    "        diseases and their seed numbers used in multixrank\n",
    "        input_nrow (int): number of lines to read in multiwrank outputs\n",
    "        output_top (int): number of top results to select for output\n",
    "        outdir (str): multixrank output directory\n",
    "        resultsdir (str): results output directory\n",
    "\n",
    "    Remark: read full output file could take time\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(f\"../multixrank_RARE_X_diseases/{resultsdir}/\", exist_ok=True)\n",
    "    for disease, seed in dico_diseases_seeds.items():\n",
    "        # Read layer 1 (rarex) output: no terms description to add\n",
    "        # because this layer contains RARE-X disease names, symptomes\n",
    "        # names and patients IDs\n",
    "        multiplex_layer1 = pd.read_csv(f\"../multixrank_RARE_X_diseases/{outdir}/output_{seed}/multiplex_Rare_X_layer.tsv\", header=0, sep=\"\\t\", nrows=input_nrow)\n",
    "        ## Remove patient nodes\n",
    "        multiplex_1_selected = multiplex_layer1[multiplex_layer1['node'].str.contains('[A-Za-z]+', regex=True)]        \n",
    "        \n",
    "        # Read layer 2 (orpha-hpo) output\n",
    "        multiplex_layer2 = pd.read_csv(f\"../multixrank_RARE_X_diseases/{outdir}/output_{seed}/multiplex_Orpha_layer.tsv\", header=0, sep=\"\\t\", nrows=input_nrow)\n",
    "        # get the nodes into a list\n",
    "        nodes_layer2 = multiplex_layer2[multiplex_layer2.columns[1]].to_list()\n",
    "        # initialize empty list to store the descriptions (orpha names and phenotyes names) for each node\n",
    "        list_description_layer2 = list()\n",
    "        # browse nodes in mutliplex 2 to add description\n",
    "        for term in nodes_layer2:\n",
    "            if term[:5] == \"ORPHA\":\n",
    "                orpha_code = term[6:]\n",
    "                orpha_name = find_orpha_name(orpha_code=orpha_code)\n",
    "                list_description_layer2.append(orpha_name)\n",
    "            elif term[:2] == \"HP\":\n",
    "                try:\n",
    "                    hpo_phenotype = Ontology.get_hpo_object(term)\n",
    "                    list_description_layer2.extend([str(hpo_phenotype)[13:]])\n",
    "                # if there is no match of HPO phenotype name\n",
    "                except RuntimeError:\n",
    "                    list_description_layer2.append(\"None\")\n",
    "        # check that the description list and the dataframe have the same length !\n",
    "        assert len(list_description_layer2) == len(multiplex_layer2.index)\n",
    "        # create new description columns for the terms\n",
    "        description_layer2 = pd.DataFrame(list_description_layer2, columns=['description'])\n",
    "        # create new dataframe for layer 2 containing the ranking of the nodes + their description (orpha names and phenotypes names)\n",
    "        multiplex_2_with_description = pd.concat([multiplex_layer2.reindex(range(len(multiplex_layer2))), description_layer2.reindex(range(len(multiplex_layer2)))], axis=1)\n",
    "        \n",
    "        # Select top of results\n",
    "        multiplex_1_head = multiplex_1_selected.reset_index(drop=True).head(21)\n",
    "        multiplex_1_head[\"empty\"] = \"\"\n",
    "        multiplex_2_head = multiplex_2_with_description.reset_index(drop=True).head(21)\n",
    "        \n",
    "        # concatenate the two dataframes and generate table output\n",
    "        table_results = pd.concat([multiplex_1_head, multiplex_2_head], axis=1)\n",
    "        table_results.to_csv(f\"../multixrank_RARE_X_diseases/{resultsdir}/results_disease_{seed}.tsv\", sep=\"\\t\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multixrank on Disease-Disease phenotype network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "outdir = \"output_DiseaseDisease_Phenotype\"\n",
    "resultsdir = \"results_output_DiseaseDisease_Phenotype\"\n",
    "input_nrow = 1000\n",
    "output_top = 21\n",
    "\n",
    "## Results integration\n",
    "create_results_table(dico_diseases_seeds=dico_diseases_seeds,\n",
    "                     input_nrow=input_nrow, \n",
    "                     output_top=output_top,\n",
    "                     outdir=outdir, \n",
    "                     resultsdir=resultsdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To concatenate all files into one, with an empty line between each result\n",
    "# rm results_output_DiseaseDisease_Phenotype.tsv\n",
    "# for i in `ls -v`; do echo $i >> results_output_DiseaseDisease_Phenotype.tsv; sed -s -e $'$a\\\\\\n' $i >> results_output_DiseaseDisease_Phenotype.tsv ; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With weighted between disease orphanet and hpo phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association between disease and phenotype:\n",
    "\n",
    "- obligate (100%) -> weight = 1\n",
    "- very frequent (99-80%) -> weight = 4/5\n",
    "- frequent (79-30%) -> weight = 3/5\n",
    "- occasional (29-5%) -> weight = 2/5\n",
    "- very rare (<4-1%) -> weight = 1/5\n",
    "- excluded (0%) -> weight = 0\n",
    "\n",
    "Association between disease and disease (association if one mutated genes shared) -> weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "outdir = \"output_DiseaseDisease_Phenotype_Weighted\"\n",
    "resultsdir = \"results_output_DiseaseDisease_Phenotype_Weighted\"\n",
    "input_nrow = 1000\n",
    "output_top = 21\n",
    "\n",
    "## Results integration\n",
    "create_results_table(dico_diseases_seeds=dico_diseases_seeds,\n",
    "                     input_nrow=input_nrow, \n",
    "                     output_top=output_top,\n",
    "                     outdir=outdir, \n",
    "                     resultsdir=resultsdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To concatenate all files into one, with an empty line between each result\n",
    "# rm results_output_DiseaseDisease_Phenotype_Weighted.tsv\n",
    "# for i in `ls -v`; do echo $i >> results_output_DiseaseDisease_Phenotype_Weighted.tsv; sed -s -e $'$a\\\\\\n' $i >> results_output_DiseaseDisease_Phenotype_Weighted.tsv ; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With weighted inverse between disease orphanet and hpo phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association between disease and phenotype:\n",
    "\n",
    "- obligate (100%) -> weight = 1/5\n",
    "- very frequent (99-80%) -> weight = 2/5\n",
    "- frequent (79-30%) -> weight = 3/5\n",
    "- occasional (29-5%) -> weight = 4/5\n",
    "- very rare (<4-1%) -> weight = 1\n",
    "- excluded (0%) -> weight = 0\n",
    "\n",
    "/!\\ Weights are inversed compared to the previous analysis\n",
    "\n",
    "Association between disease and disease (association if one mutated genes shared) -> weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "outdir = \"output_DiseaseDisease_Phenotype_WeightedInverse\"\n",
    "resultsdir = \"results_output_DiseaseDisease_Phenotype_WeightedInverse\"\n",
    "input_nrow = 1000\n",
    "output_top = 21\n",
    "\n",
    "## Results integration\n",
    "create_results_table(dico_diseases_seeds=dico_diseases_seeds,\n",
    "                     input_nrow=input_nrow, \n",
    "                     output_top=output_top,\n",
    "                     outdir=outdir, \n",
    "                     resultsdir=resultsdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To concatenate all files into one, with an empty line between each result\n",
    "# rm results_output_DiseaseDisease_Phenotype_WeightedInverse.tsv\n",
    "# for i in `ls -v`; do echo $i >> results_output_DiseaseDisease_Phenotype_WeightedInverse.tsv; sed -s -e $'$a\\\\\\n' $i >> results_output_DiseaseDisease_Phenotype_WeightedInverse.tsv ; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multixrank on Disease-Disease phenotype with phenotype ontology network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "outdir = \"output_DiseaseDisease_PhenotypeOntology\"\n",
    "resultsdir = \"results_output_DiseaseDisease_PhenotypeOntology\"\n",
    "input_nrow = 1000\n",
    "output_top = 21\n",
    "\n",
    "## Results integration\n",
    "create_results_table(dico_diseases_seeds=dico_diseases_seeds,\n",
    "                     input_nrow=input_nrow, \n",
    "                     output_top=output_top,\n",
    "                     outdir=outdir, \n",
    "                     resultsdir=resultsdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To concatenate all files into one, with an empty line between each result\n",
    "# rm results_output_DiseaseDisease_PhenotypeOntology.tsv\n",
    "# for i in `ls -v`; do echo $i >> results_output_DiseaseDisease_PhenotypeOntology.tsv; sed -s -e $'$a\\\\\\n' $i >> results_output_DiseaseDisease_PhenotypeOntology.tsv ; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With weighted between disease orphanet and hpo phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association between disease and phenotype:\n",
    "\n",
    "- obligate (100%) -> weight = 1\n",
    "- very frequent (99-80%) -> weight = 4/5\n",
    "- frequent (79-30%) -> weight = 3/5\n",
    "- occasional (29-5%) -> weight = 2/5\n",
    "- very rare (<4-1%) -> weight = 1/5\n",
    "- excluded (0%) -> weight = 0\n",
    "\n",
    "Association between phenotype and phenotype (phenotype hierarchy) -> weight = 0.2\n",
    "\n",
    "Association between disease and disease (association if one mutated genes shared) -> weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "outdir = \"output_DiseaseDisease_PhenotypeOntology_Weighted\"\n",
    "resultsdir = \"results_output_DiseaseDisease_PhenotypeOntology_Weighted\"\n",
    "input_nrow = 1000\n",
    "output_top = 21\n",
    "\n",
    "## Results integration\n",
    "create_results_table(dico_diseases_seeds=dico_diseases_seeds,\n",
    "                     input_nrow=input_nrow, \n",
    "                     output_top=output_top,\n",
    "                     outdir=outdir, \n",
    "                     resultsdir=resultsdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To concatenate all files into one, with an empty line between each result\n",
    "# rm results_output_DiseaseDisease_PhenotypeOntology_Weighted.tsv\n",
    "# for i in `ls -v`; do echo $i >> results_output_DiseaseDisease_PhenotypeOntology_Weighted.tsv; sed -s -e $'$a\\\\\\n' $i >> results_output_DiseaseDisease_PhenotypeOntology_Weighted.tsv ; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With weighted inverse between disease orphanet and hpo phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association between disease and phenotype:\n",
    "\n",
    "- obligate (100%) -> weight = 1/5\n",
    "- very frequent (99-80%) -> weight = 2/5\n",
    "- frequent (79-30%) -> weight = 3/5\n",
    "- occasional (29-5%) -> weight = 4/5\n",
    "- very rare (<4-1%) -> weight = 1\n",
    "- excluded (0%) -> weight = 0\n",
    "\n",
    "/!\\ Weights are inversed compared to the previous analysis\n",
    "\n",
    "Association between phenotype and phenotype (phenotype hierarchy) -> weight = 0.2\n",
    "\n",
    "Association between disease and disease (association if one mutated genes shared) -> weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "outdir = \"output_DiseaseDisease_PhenotypeOntology_WeightedInverse\"\n",
    "resultsdir = \"results_output_DiseaseDisease_PhenotypeOntology_WeightedInverse\"\n",
    "input_nrow = 1000\n",
    "output_top = 21\n",
    "\n",
    "## Results integration\n",
    "create_results_table(dico_diseases_seeds=dico_diseases_seeds,\n",
    "                     input_nrow=input_nrow, \n",
    "                     output_top=output_top,\n",
    "                     outdir=outdir, \n",
    "                     resultsdir=resultsdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To concatenate all files into one, with an empty line between each result\n",
    "# rm results_output_DiseaseDisease_PhenotypeOntology_WeightedInverse.tsv\n",
    "# for i in `ls -v`; do echo $i >> results_output_DiseaseDisease_PhenotypeOntology_WeightedInverse.tsv; sed -s -e $'$a\\\\\\n' $i >> results_output_DiseaseDisease_PhenotypeOntology_WeightedInverse.tsv ; done\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
